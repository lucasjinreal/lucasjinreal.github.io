<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Fagang Jin</title>

  <meta name="author" content="Fagang Jin">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Fagang Jin
                  </p>
                  <p>I'm a research scientist and engineer at <a href="https://www.tencent.com/">Tencent</a> since 2021,
                    where I
                    lead a small
                    team primarily dedicated to <a href="https://www.matthewtancik.com/nerf">Multi-Modal
                      Understanding</a>. I previously joined <a href="https://www.autox.ai/">AutoX</a> as an Autonomous
                    Driving Senior Engineer, working with <a
                      href="https://alum.hkust.edu.hk/entrepreneurship/1257/jianxiong_xiao">Prof. JianXiong
                      Xiao</a>(Known as Prof.X) since 2019, where I leading a
                    small team doing work on Computer Vision in automomous driving field.
                  </p>
                  <p>
                    Beforehead, I have been intern at Tencent AutoLab (Autonmous Driving Research Lab). I have also been
                    intern at DiDi, working with <a href="https://www.cityu.edu.hk/merc/pplyanqx.aspx">Dr. QingXiong
                      Yang.</a>
                  </p>

                  <p>
                    I hold a master's degree from <a href="https://www.csu.edu.cn/">Central South University</a>, major
                    in Control Science and Engineering.
                    Furthermore,
                    I spent a semester as an exchange student at the <a href="https://www.upenn.edu/">University of
                      Pennsylvania</a> during my undergraduate studies.
                  </p>
                  <p style="text-align:center">
                    <a href="jinfagang19@163.com">Email</a> &nbsp;/&nbsp;
                    <a href="assets/cv.pdf">CV</a> &nbsp;/&nbsp;
                    <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                    <!-- <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Scholar</a> &nbsp;/&nbsp; -->
                    <a href="https://www.zhihu.com/people/jin-tian-33-40">Zhihu</a> &nbsp;/&nbsp;
                    <a href="https://github.com/lucasjinreal/">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="assets/fg.webp"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;"
                      alt="profile photo" src="assets/fg.webp" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my
                    research is about refering to taught AI doing things. Currently obessed on GeneratetiveAI in both
                    video & image understanding and generation. Representative papers are <span
                      class="highlight">highlighted</span>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='smerf_image'><video width=100% muted autoplay loop>
                        <source src="images/smerf.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='https://monolithfoundation.github.io/project_bumblebee/static/images/board.jpg'
                      width=100%>
                  </div>
                  <script type="text/javascript">
                    function smerf_start() {
                      document.getElementById('smerf_image').style.opacity = "1";
                    }

                    function smerf_stop() {
                      document.getElementById('smerf_image').style.opacity = "0";
                    }
                    smerf_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://lucasjinreal.github.io">
                    <span class="papertitle">Bumblebee: Advancing Beyond Closed-Source Multi-Modal Models through Token
                      Shrinkage</span>
                  </a>
                  <br>
                  <a href="http://lucasjinreal.github.io"><strong>Fagang Jin*</strong></a>,
                  <a href="https://phogzone.com/">Tong Chen*</a>,
                  <a href="https://creiser.github.io/">Lin You</a>,
                  <br>
                  <em>arXiv</em>, 2024
                  <br>
                  <a href="https://monolithfoundation.github.io/project_bumblebee/">project page</a>
                  /
                  <a href="https://github.com/MonolithFoundation/Bumblebee">github</a>
                  <!-- /
                  <a href="https://arxiv.org/abs/2312.07541">arXiv</a> -->
                  <p></p>
                  <p>
                    Surpassed QwenVL-Max and Yi-VL-34B on MMB-CN test with only 14B params, remarkably strengthed
                    opensource MLLM ability through token distillation. (papers are not open at the moment due to
                    company
                    regulations, weights are open)
                  </p>
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Projects</h2>
                  <p>
                    I have huge entusiasim to contribute to opensource, I have many very good opensourced projects being
                    popular by community. I an very happy to help people who loved technology and AI just like me from
                    bottom of heart. The most popular projects are <span class="highlight">highlighted</span>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>


              <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='smerf_image'><video width=100% muted autoplay loop>
                        <source src="images/smerf.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img
                      src='https://gitcode.net/godofgodofgod/gerg/-/raw/main/pictures/2024/05/8_23_51_34_202405082351399.png'
                      width=100%>
                  </div>
                  <script type="text/javascript">
                    function smerf_start() {
                      document.getElementById('smerf_image').style.opacity = "1";
                    }

                    function smerf_stop() {
                      document.getElementById('smerf_image').style.opacity = "0";
                    }
                    smerf_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://lucasjinreal.github.io">
                    <span class="papertitle">MLLM: Our first try on large models, the first product Bumblebee shows a
                      nice performance on image understanding.</span>
                  </a>
                  <br>
                  <a href="http://lucasjinreal.github.io"><strong>Fagang Jin*</strong></a>,
                  <br>
                  <em>opensource</em>, 2021
                  <br>
                  <a href="https://github.com/lucasjinreal/yolov7_d2">project page</a>
                  /
                  <a href="https://github.com/lucasjinreal/yolov7_d2">github </a>
                  <!-- /
                <a href="https://arxiv.org/abs/2312.07541">arXiv</a> -->
                  <p></p>
                  <p>
                    Our first try on multi modal large language models for understanding, in the V1 version, with apply
                    a dual tower model design outputs 576 tokens to LLM, surpassed QwenVL Max on MMB-CN test set, shows
                    a promising ability on understanding image and reading texts.
                  </p>
                  <p>
                  </p>
                </td>
              </tr>


              <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='smerf_image'><video width=100% muted autoplay loop>
                        <source src="images/smerf.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img
                      src='https://gitcode.net/godofgodofgod/gerg/-/raw/main/pictures/2024/05/8_23_44_47_%E5%B1%8F%E5%B9%95%E5%BD%95%E5%88%B62022-04-10%20%E4%B8%8B%E5%8D%8810.43.08.gif'
                      width=100%>
                  </div>
                  <script type="text/javascript">
                    function smerf_start() {
                      document.getElementById('smerf_image').style.opacity = "1";
                    }

                    function smerf_stop() {
                      document.getElementById('smerf_image').style.opacity = "0";
                    }
                    smerf_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://lucasjinreal.github.io">
                    <span class="papertitle">RTMP: A RealTime Motion Capture System Powered by Lighted Detection and
                      Pose, with 3D Pose Estimation in Pure C++</span>
                  </a>
                  <br>
                  <a href="http://lucasjinreal.github.io"><strong>Fagang Jin*</strong></a>,
                  <br>
                  <em>projects</em>, 2021
                  <br>
                  <!-- <a href="https://github.com/lucasjinreal/yolov7_d2">project page</a>
                  /
                  <a href="https://github.com/lucasjinreal/yolov7_d2">github </a> -->
                  <!-- /
                <a href="https://arxiv.org/abs/2312.07541">arXiv</a> -->
                  <p></p>
                  <p>
                    A Real-Time Mocap System, powered by a lightweight detection model and 3D pose regression, is fully
                    implemented in C++ for integration with UnrealEngine. This project offers an enjoyable introduction
                    to UnrealEngine and MetaHumans.
                  </p>
                  <p>
                  </p>
                </td>
              </tr>

              <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='smerf_image'><video width=100% muted autoplay loop>
                        <source src="images/smerf.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='https://gitcode.net/godofgodofgod/gerg/-/raw/main/pictures/2024/05/8_22_43_12_aa.gif'
                      width=100%>
                  </div>
                  <script type="text/javascript">
                    function smerf_start() {
                      document.getElementById('smerf_image').style.opacity = "1";
                    }

                    function smerf_stop() {
                      document.getElementById('smerf_image').style.opacity = "0";
                    }
                    smerf_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://lucasjinreal.github.io">
                    <span class="papertitle">YOLOv7: DETR, DINO, MobileOne, EfficientFormer... Detection, Keypoints,
                      Segmentation, One Framework to Rule them All.</span>
                  </a>
                  <br>
                  <a href="http://lucasjinreal.github.io"><strong>Fagang Jin*</strong></a>,
                  <br>
                  <em>opensource</em>, 2021
                  <br>
                  <a href="https://github.com/lucasjinreal/yolov7_d2">project page</a>
                  /
                  <a href="https://github.com/lucasjinreal/yolov7_d2">github </a>
                  <!-- /
                <a href="https://arxiv.org/abs/2312.07541">arXiv</a> -->
                  <p></p>
                  <p>
                    YOLOv7-D2 merges convolution methods and transformers method over several different computer vision
                    tasks into a single framework. Received over 3.1k stars and ~450 forks overtime.
                  </p>
                  <p>
                    <iframe
                      src="https://ghbtns.com/github-btn.html?user=lucasjinreal&repo=yolov7_d2&type=star&count=true"
                      frameborder="0" scrolling="0" width="130" height="20" title="GitHub"></iframe>
                    <iframe
                      src="https://ghbtns.com/github-btn.html?user=lucasjinreal&repo=yolov7_d2&type=fork&count=true&size=small"
                      frameborder="0" scrolling="0" width="130" height="20" title="GitHub"></iframe>
                  </p>
                </td>
              </tr>

              <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='smerf_image'><video width=100% muted autoplay loop>
                        <source src="images/smerf.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img
                      src='https://gitcode.net/godofgodofgod/gerg/-/raw/main/pictures/2024/05/8_23_1_23_stacked_img.jpg'
                      width=100%>
                  </div>
                  <script type="text/javascript">
                    function smerf_start() {
                      document.getElementById('smerf_image').style.opacity = "1";
                    }

                    function smerf_stop() {
                      document.getElementById('smerf_image').style.opacity = "0";
                    }
                    smerf_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://lucasjinreal.github.io">
                    <span class="papertitle">Wanwu: An Unified inference framework with various backend, Switch between
                      TensorRT/ONNXRuntime/MNN at ease</span>
                  </a>
                  <br>
                  <a href="http://lucasjinreal.github.io"><strong>Fagang Jin*</strong></a>,
                  <br>
                  <em>opensource</em>, 2022
                  <br>
                  <a href="https://github.com/lucasjinreal/wanwu">project page</a>
                  /
                  <a href="https://github.com/lucasjinreal/wanwu">github </a>
                  <!-- /
                <a href="https://arxiv.org/abs/2312.07541">arXiv</a> -->
                  <p></p>
                  <p>
                    Wanwu make DL models inference easier, with a inference backend seperated design, it can be deployed
                    to anywhere with just a single ONNX model file. And runs extremly fast on any devices. Also comes
                    along with many out-of-box models such as YOLOv5, YOLOv7, YOLOv7-Keypoints, Tracking, FaceDetection
                    etc.
                  </p>
                  <p>
                  </p>
                </td>
              </tr>

              <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='smerf_image'><video width=100% muted autoplay loop>
                        <source src="images/smerf.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img
                      src='https://gitcode.net/godofgodofgod/gerg/-/raw/main/pictures/2024/05/8_23_26_42_68747470733a2f2f73342e617831782e636f6d2f323032322f30312f31382f374244555a6e2e676966.gif'
                      width=100%>
                  </div>
                  <script type="text/javascript">
                    function smerf_start() {
                      document.getElementById('smerf_image').style.opacity = "1";
                    }

                    function smerf_stop() {
                      document.getElementById('smerf_image').style.opacity = "0";
                    }
                    smerf_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://lucasjinreal.github.io">
                    <span class="papertitle">Alfred: A Deeplearning utils lib for visualization 2D and 3D.</span>
                  </a>
                  <br>
                  <a href="http://lucasjinreal.github.io"><strong>Fagang Jin*</strong></a>,
                  <br>
                  <em>opensource</em>, 2020
                  <br>
                  <a href="https://github.com/lucasjinreal/wanwu">project page</a>
                  /
                  <a href="https://github.com/lucasjinreal/wanwu">github </a>
                  <!-- /
                <a href="https://arxiv.org/abs/2312.07541">arXiv</a> -->
                  <p>
                    Alfred-py make visualization simple, not only 2D box, mask, keypoints, but also 3D mesh,
                    3d-keypoints etc. It allows users to visualize things extremly simple and easy to use.
                  </p>
                  <p>
                    <iframe src="https://ghbtns.com/github-btn.html?user=lucasjinreal&repo=alfred&type=star&count=true"
                      frameborder="0" scrolling="0" width="130" height="20" title="GitHub"></iframe>
                    <iframe
                      src="https://ghbtns.com/github-btn.html?user=lucasjinreal&repo=alfred&type=fork&count=true&size=small"
                      frameborder="0" scrolling="0" width="130" height="20" title="GitHub"></iframe>
                  </p>
                </td>
              </tr>


            </tbody>
          </table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <h2>Miscellanea</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>

              <!-- <tr>
                <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
                <td width="75%" valign="center">
                  <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                  <br>
                  <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                  <br>
                  <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                  <br>
                  <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                  <br>
                  <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                  <br>
                  <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/cs188.jpg" alt="cs188">
                </td>
                <td width="75%" valign="center">
                  <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor,
                    CS188 Spring 2011</a>
                  <br>
                  <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor,
                    CS188 Fall 2010</a>
                  <br>
                  <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd
                    Edition</a>
                </td>
              </tr> -->


              <tr>
                <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                  <h2>Personal <br> Blog Posts (CN)</h2>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://zhuanlan.zhihu.com/p/691577097">Multi-Modal Video Understanding Based on Unified
                    Representation: Integration of Text-to-Image and Video Generations</a>
                  <br>
                  <a href="https://zhuanlan.zhihu.com/p/684394776">A Comprehensive Review of Video-Level Multi-Modal
                    Generative Models - Understanding Directions in 2024</a>
                  <br>

                  <a href="https://zhuanlan.zhihu.com/p/657894835">Latest Advances in Multi-Modal Approaches Based on
                    Large
                    Models</a>
                  <br>

                </td>
              </tr>


            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:center;font-size:small;">
                    Copyright©️2024 Fagang Jin
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>